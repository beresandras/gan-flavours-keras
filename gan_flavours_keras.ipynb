{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSRJBo9-lwOX"
      },
      "source": [
        "# GAN Flavours\n",
        "\n",
        "This jupyter notebook contains a training script for the https://github.com/beresandras/gan-flavours-keras repository, and is intended to be used in a Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Q2l8ZretUZ"
      },
      "outputs": [],
      "source": [
        "# uncomment on first run\n",
        "# !pip install tensorflow_addons\n",
        "# !git clone https://github.com/beresandras/gan-flavours-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKsXIajqePwJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "sys.path.insert(0,'/content/gan-flavours-keras')\n",
        "\n",
        "from dataset import prepare_dataset\n",
        "from architecture import get_generator, get_discriminator\n",
        "from augmentation import AdaptiveAugmenter\n",
        "from losses import (\n",
        "    MiniMaxGAN,\n",
        "    NonSaturatingGAN,\n",
        "    LeastSquaresGAN,\n",
        "    HingeGAN,\n",
        "    WassersteinGAN,\n",
        "    RelativisticGAN,\n",
        "    RelativisticAverageGAN,\n",
        ")\n",
        "from utils import generate_images_with, plot_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAXcug3LeU4P"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "\n",
        "# data\n",
        "# some datasets might be unavailable for download at times\n",
        "dataset_name = \"caltech_birds2011\"  # \"oxford_flowers102\", \"celeb_a\", \"cifar10\"\n",
        "image_size = 64  # 64, 64, 32\n",
        "num_epochs = 400  # 500, 25, 100\n",
        "kid_image_size = 75  # resolution of KID measurement, default 299\n",
        "plot_interval = 10  # 10, 1, 2\n",
        "\n",
        "# optimization\n",
        "batch_size = 128\n",
        "one_sided_label_smoothing = 0.0  # can be 0.1\n",
        "ema = 0.99\n",
        "generator_lr = 2e-4\n",
        "discriminator_lr = 2e-4\n",
        "beta_1 = 0.5\n",
        "beta_2 = 0.999\n",
        "\n",
        "# architecture\n",
        "noise_size = 64\n",
        "depth = 4  # number of up- and downsampling layers, change with resolution\n",
        "width = 128\n",
        "initializer = \"glorot_uniform\"\n",
        "residual = False\n",
        "transposed = True  # transposed convs vs upsampling + convs in generator\n",
        "leaky_relu_slope = 0.2\n",
        "dropout_rate = 0.4\n",
        "spectral_norm = False\n",
        "\n",
        "# adaptive discriminator augmentation\n",
        "target_accuracy = None  # 0.85, set to None to disable\n",
        "integration_steps = 1000\n",
        "max_probability = 0.8  # maximal augmentation probability\n",
        "\n",
        "id = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKX-vD2jeVLe"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "train_dataset = prepare_dataset(dataset_name, \"train\", image_size, batch_size)\n",
        "val_dataset = prepare_dataset(dataset_name, \"validation\", image_size, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3NnbOlWeVXN"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "model = NonSaturatingGAN(\n",
        "    id=id,\n",
        "    generator=get_generator(\n",
        "        noise_size, depth, width, initializer, residual, transposed\n",
        "    ),\n",
        "    discriminator=get_discriminator(\n",
        "        image_size,\n",
        "        depth,\n",
        "        width,\n",
        "        initializer,\n",
        "        residual,\n",
        "        leaky_relu_slope,\n",
        "        dropout_rate,\n",
        "        spectral_norm,\n",
        "    ),\n",
        "    augmenter=AdaptiveAugmenter(\n",
        "        target_accuracy=target_accuracy,\n",
        "        integration_steps=integration_steps,\n",
        "        max_probability=max_probability,\n",
        "        input_shape=(image_size, image_size, 3),\n",
        "    ),\n",
        "    one_sided_label_smoothing=one_sided_label_smoothing,\n",
        "    ema=ema,\n",
        "    kid_image_size=kid_image_size,\n",
        "    plot_interval=plot_interval,\n",
        "    is_jupyter=True,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    generator_optimizer=keras.optimizers.Adam(\n",
        "        learning_rate=generator_lr, beta_1=beta_1, beta_2=beta_2\n",
        "    ),\n",
        "    discriminator_optimizer=keras.optimizers.Adam(\n",
        "        learning_rate=discriminator_lr, beta_1=beta_1, beta_2=beta_2\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCBVd6DBeViQ"
      },
      "outputs": [],
      "source": [
        "# checkpointing\n",
        "checkpoint_path = \"checkpoints/model_{}\".format(id)\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_kid\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# run training\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[\n",
        "        keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
        "        checkpoint_callback,\n",
        "    ],\n",
        ")\n",
        "\n",
        "# load best model\n",
        "model.load_weights(checkpoint_path)\n",
        "generate_images_with(model, history, id, is_jupyter=True)\n",
        "\n",
        "# plot history\n",
        "plot_history(history, id, is_jupyter=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "contrastive-classification-keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
